{
priv enum Token {
  WHITESPACE
  NUMBER(String)
  STRING(String)
  LBRACE
  RBRACE
  LBRACKET
  RBRACKET
  COMMA
  COLON
  TRUE
  FALSE
  NULL
} derive(ToJson)

pub type! LexError {
  EndOfFile
  UnexpectedEndOfFile
  Unrecognized(String)
}
}

rule token[T](lexbuf : @lexbuf.T[T, String, Int]) -> Token!LexError {
  parse {
    [' ' '\t' '\r' '\n'] => { WHITESPACE }
    ('-'? ('0' | ['1'-'9'] ['0'-'9']* ('.' ['0'-'9']+)?) (['E' 'e'] ['+' '-']? ['0'-'9']+)?) as t => { NUMBER(t) }
    '"' as t => {
      let buf = StringBuilder::new()
      buf.write_string(t)
      lex_string!(buf, lexbuf)
      STRING(buf.to_string())
    }
    '{' => { LBRACE }
    '}' => { RBRACE }
    '[' => { LBRACKET }
    ']' => { RBRACKET }
    ',' => { COMMA }
    ':' => { COLON }
    "true" => { TRUE }
    "false" => { FALSE }
    "null" => { NULL }
    _ as t => { raise(Unrecognized(t)) }
    "" => { raise(EndOfFile) }
  }
}

rule lex_string[T](buf : StringBuilder, lexbuf : @lexbuf.T[T, String, Int]) -> Unit!LexError {
  parse {
    '"' as t => { buf.write_string(t) }
    ( '\\' '"'
    | '\\' '\\'
    | '\\' '/'
    | '\\' 'b'
    | '\\' 'f'
    | '\\' 'n'
    | '\\' 'r'
    | '\\' 't'
    | '\\' 'u' ['0'-'9' 'A'-'F' 'a'-'f'] ['0'-'9' 'A'-'F' 'a'-'f'] ['0'-'9' 'A'-'F' 'a'-'f'] ['0'-'9' 'A'-'F' 'a'-'f']) as t => { 
      buf.write_string(t)
      lex_string!(buf, lexbuf)
    }
    [^ '"' '\\' '\x00'-'\x1F' '\x7f'] as t => { 
      buf.write_string(t)
      lex_string!(buf, lexbuf)
    }
    _ as t => { raise(Unrecognized(t)) }
    "" => { raise(UnexpectedEndOfFile) }
  }
}

{
}
